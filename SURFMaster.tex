\documentclass{article}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{timeline}
\usepackage{booktabs}
\usepackage{float}
\restylefloat{table}
\graphicspath{ {../} }
\usepackage[margin={1.5cm,2cm}]{geometry}
\usepackage{multicol}
\setlength\columnsep{1.5cm}
\usepackage{tabto}
\usepackage{pdflscape}
\usepackage{graphicx}
\usepackage{array}

\begin{document}
\begin{titlepage}
	\centering
	\begin{figure}[H]
	\centering
	%\includegraphics[scale=0.5]{logo_nasa_trio_black@2x.png}
	\end{figure}
	\vspace{2cm}
	{\scshape\LARGE NCRA-TIFR Project Proposal \par}
	\vspace{2cm}
	{\huge\bfseries \par}
	\vspace{2cm}
	{\Large\itshape Archit Sakhadeo\par}
	{\Large\itshape Rathin Desai\par}
	{\Large\itshape Shadab Shaikh\par}
	{\Large\itshape Shubhankar Deshpande\par}
	\vfill
	Mentor\par
	Dr. Yogesh  \textsc{Wadadekar}
	\par
	Dr. C. H. Ishwar \textsc{Chandra}

	\vfill

\end{titlepage}
\begin{multicols*}{2}
\section{Morphological Classes of Radio Galaxies}
\newline Radio galaxies with active nuclei can be distinguished based on their radio luminosity or brightness of their radio emissions in relation to their hosting environment. Some of the basic morphological classifications include point sources, extended sources i.e. sources with extended contours, double radio sources, jets, and lobes.


\section{Problems faced with current classification}


Currently Radio astronomers manually classify galaxies based on visual inspection of the images which, we are afraid, is slow, introduces uncertainities and something we believe is not a worthy activity for a radio astronomer to be engaged in. 

Also, most algorithms have been used to classify just two object classes at a time. What we aim to achieve is build a robust model capable of handling more than 2 classes.




\section{Objective}

\begin{itemize}
	\item Exploring rare galaxies by classifying them into a special category other than the ones mentioned in section yy.
	\item Effectively reduce the efforts put in by radio astronomers without affecting accuracy.
\end{itemize}




\section{Approaches used for this problem}
\newline As far as we know, no method has been employed for this task.


 
\section{Our Proposed method}
\subsection{Extracting sources from the FITS image using PyBDSM}
  By Shubhankar
\subsection{Cropping each individual source to work on it individually}
 On the basis of RA(Right Ascension) and Dec (Declination) values generated from section 5.1, we then convert it to its corresponding pixel values in the original fits image. Based on these pixel values we crop a 10*10 patches of image with the source coordinates at the centre.

\subsection{Preprocessing of the data}

\begin{itemize}
\item Image Processing techniques
\end{itemize}

\subsection{Analytical Method}

Two broad steps that we plan to use: 
\begin{itemize}
	\item Statistical modelling of data to manually extract features. We plan to employ Scale-invariant feature transform (SIFT) algorithm to detect the features.  
	\item Classification of the radio galaxies based on these extracted features. Possible approaches : Naive Bayes, SVM and Random Forests.
\end{itemize}


\subsection{Empirical Approach}

We plan to deploy a Convolutional Neural Network model for classification which reduces the manual feature engineering part, and has achieved significant successes in object recognition and image classification tasks. ( Give References to papers) 
    


\section{How we predict it will solve the problem}

\section{Approximate timeline of completing the whole project}
\begin{itemize}
	\item 26th April to 11th May - literature survey
	\item Mid-August to October - working on basic prototype model individually by trying out multiple approaches
	\item October to November - choosing the approaches which work, and implementing them on all data, validation of the results.
	\item November to December - Refining the system, cleaning and commenting the code
\end{itemize} 





\section{Data used}
    TIFR GMRT Sky Survey data shall be used along with the data processed from GMRT cycle 20. We plan to use the data from other cycles once it has been run through our SPAM pipeline. 


\end{document}
