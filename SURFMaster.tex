\documentclass{article}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{timeline}
\usepackage{booktabs}
\usepackage{float}
\restylefloat{table}
\graphicspath{{images/}}
\usepackage[margin={1.5cm,2cm}]{geometry}
\usepackage{multicol}
\setlength\columnsep{1.5cm}
\usepackage{tabto}
\usepackage{pdflscape}
\usepackage{graphicx}
\usepackage{array}


\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{charter}
\usepackage{environ}
\usepackage{tikz}
\usetikzlibrary{calc,matrix}

% code by Andrew:
% http://tex.stackexchange.com/a/28452/13304
\makeatletter
\let\matamp=&
\catcode`\&=13
\makeatletter
\def&{\iftikz@is@matrix
  \pgfmatrixnextcell
  \else
  \matamp
  \fi}
\makeatother

\newcounter{lines}
\def\endlr{\stepcounter{lines}\\}

\newcounter{vtml}
\setcounter{vtml}{0}

\newif\ifvtimelinetitle
\newif\ifvtimebottomline
\tikzset{description/.style={
  column 2/.append style={#1}
 },
 timeline color/.store in=\vtmlcolor,
 timeline color=red!80!black,
 timeline color st/.style={fill=\vtmlcolor,draw=\vtmlcolor},
 use timeline header/.is if=vtimelinetitle,
 use timeline header=false,
 add bottom line/.is if=vtimebottomline,
 add bottom line=false,
 timeline title/.store in=\vtimelinetitle,
 timeline title={},
 line offset/.store in=\lineoffset,
 line offset=4pt,
}

\NewEnviron{vtimeline}[1][]{%
\setcounter{lines}{1}%
\stepcounter{vtml}%
\begin{tikzpicture}[column 1/.style={anchor=east},
 column 2/.style={anchor=west},
 text depth=0pt,text height=1ex,
 row sep=1ex,
 column sep=1em,
 #1
]
\matrix(vtimeline\thevtml)[matrix of nodes]{\BODY};
\pgfmathtruncatemacro\endmtx{\thelines-1}
\path[timeline color st] 
($(vtimeline\thevtml-1-1.north east)!0.5!(vtimeline\thevtml-1-2.north west)$)--
($(vtimeline\thevtml-\endmtx-1.south east)!0.5!(vtimeline\thevtml-\endmtx-2.south west)$);
\foreach \x in {1,...,\endmtx}{
 \node[circle,timeline color st, inner sep=0.15pt, draw=white, thick] 
 (vtimeline\thevtml-c-\x) at 
 ($(vtimeline\thevtml-\x-1.east)!0.5!(vtimeline\thevtml-\x-2.west)$){};
 \draw[timeline color st](vtimeline\thevtml-c-\x.west)--++(-3pt,0);
 }
 \ifvtimelinetitle%
  \draw[timeline color st]([yshift=\lineoffset]vtimeline\thevtml.north west)--
  ([yshift=\lineoffset]vtimeline\thevtml.north east);
  \node[anchor=west,yshift=16pt,font=\large]
   at (vtimeline\thevtml-1-1.north west) 
   {\textsc{Timeline \thevtml}: \textit{\vtimelinetitle}};
 \else%
  \relax%
 \fi%
 \ifvtimebottomline%
   \draw[timeline color st]([yshift=-\lineoffset]vtimeline\thevtml.south west)--
  ([yshift=-\lineoffset]vtimeline\thevtml.south east);
 \else%
   \relax%
 \fi%
\end{tikzpicture}
}




\begin{document}
\begin{titlepage}
	\centering
	\begin{figure}[H]
	\centering
	%\includegraphics[scale=0.5]{logo_nasa_trio_black@2x.png}
	\end{figure}
	\vspace{2cm}
	{\scshape\LARGE NCRA-TIFR Project Proposal \par}
	\vspace{2cm}
	{\huge\bfseries \par}
	\center\includegraphics[scale=0.5]{NCRATIFR.jpg}
	
	\vspace{2cm}
	{\Large\itshape Archit Sakhadeo\par}
	{\Large\itshape Rathin Desai\par}
	{\Large\itshape Shadab Shaikh\par}
	{\Large\itshape Shubhankar Deshpande\par}
	\vfill
	Mentor\par
	Dr. Yogesh  \textsc{Wadadekar}
	\par
	Dr. C. H. Ishwar \textsc{Chandra}

	\vfill

\end{titlepage}
\begin{multicols*}{2}
\section{Introduction}
\subsection{Morphological Classes of Radio Galaxies}

Radio galaxies with active nuclei can be distinguished based on their radio luminosity or brightness of their radio emissions in relation to their hosting environment. Some of the basic morphological classifications include point sources, extended sources i.e. sources with extended contours, double radio sources, jets, and lobes.


\subsection{Problems faced with current classification}

Currently Radio astronomers manually classify galaxies based on visual inspection of the images which is a slow procedure, and increases the time to production of scientific results. Further, it introduces uncertainities in the classification procedure, both of which are problems which can potentially be mitigated by using an automated approach.

Contemporary algorithms classify radio sources into at most three different classes. Our aim is to build a robust model capable of handling more than 2 classes.

\section{Objective}

\begin{itemize}
	\item Potentially discovering rare forms of radio sources by classification in different classes.
	\item Reduction in time to generate scientific results by radio astronomers.
	\item Deeper insight into topological representation of radio data during classification.
\end{itemize}

\section{Approach}

\subsection{Source Modelling}
  The first step would be source extraction using the standard technique of gaussian modelling. We propose to do this using the robust PyBDSM pipeline used for fitting gaussian distributions to radio sources. The software contains a plethora of features, from which we would be using a small subset. This would mainly include:

\begin{enumerate}
\item Source extraction using gaussian modelling of radio data.
\item Generation of a catalog file containing details of radio sources (RA, DEC, Size of Gaussian (min, max), etc.)
\end{enumerate}

\subsection{Cutout Generation}
The second step would be to convert the RA(Right Ascension) and DEC (Declination) values generated from the catalog, to their corresponding pixel values in the original image. Based on these pixel values we generate 10*10 px cutouts using as reference the co-ordinates of the center of the radio source. This involves a multistep procedure briefly including:
\begin{enumerate}
\item Reading the FITS image in the form of a matrix
\item Parsing through the generated catalog file and extracting data for each radio source such as RA, DEC, etc.
\item Converting the RA and DEC values from WCS (World Coordinate System) to pixel values.
\item Processing pixel values to account for difference in addressing between FORTRAN and C family of languages.
\item Slicing the image matrix assuming the reference pixel co-ordinates as the center of the source.
\end{enumerate}

Prototype code for section \textit{3.1} and section \textit{3.2} has been written mainly for testing purposes. We used a sample image from the TGSS survey which was then processed using the first two steps of our pipeline to generate 470 cutout images.
More details can be found at: 
https://github.com/NCRA-TIFR/radiogen.

\subsection{Data Preprocessing}
\subsubsection{Input data}
We'll generate cutouts (as mentioned in section 3.2) from every image 
in the TGSS survey. We'll have approximately 5500 * 470 i.e. 2585000 patches of image. 

There are three common forms of data preprocessing image data:

\begin{itemize}
\item Mean subtraction : It involves subtracting the mean, of the all the pixels, across every feature in the data.

\item Normalization : It involves normalizing the data dimensions so that they are of approximately the same scale. It effectively changes the range of pixel intensity values
\end{itemize}

\subsubsection{Dimensionality reduction}
Dimensionality reduction is the process of reducing the number of random variables under consideration. It transforms the images in the high-dimensional space to a space of lesser dimensions.

Some of the common forms of 

\begin{itemize}
	\item \textbf{Mean Subtraction}
\end{itemize}
\subsection{Analytical Approach}

Two broad steps that we plan to use: 
\begin{itemize}
	\item Statistical modelling of data to manually extract features. We plan to employ Scale-invariant feature transform (SIFT) algorithm to detect the features.  
	\item Classification of the radio galaxies based on these extracted features. Possible approaches : Naive Bayes, SVM and Random Forests.
\end{itemize}


\subsection{Empirical Approach}

Empirical approach is a way of gaining knowledge by means of direct and indirect observation or experience. In the context of this project, we plan to employ Artificial Neural Networks(ANNs), which are a computational model based on large collection of simple artifical neurons, that learns hierarchical representations of the observational data. Each neural unit is connected with many other units which computes using summation function. Neural networks typically consist of multiple layers in which a signal traverses from the first(input)  to the last (output) layer of neural units.

Convolutional neural networks(CNNs), a particular type of ANN, currently provide the best solutions to many problems in computer vision such as  image segmentation, recognition and classification\cite{alex}.

Convolutional neural networks were designed to use minimal amounts of preprocessing. A typical architecture of a CNN consists of convolutional layers, activation layers and pooling layers. Convolutional layer performs the convolution operation on previous layers, activation layer defines the output of that node given an input or set of inputs, and the pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters and amount of computation in the network.
    
The initial layers of the CNNs learn simple features in the input data such as straight edges, simple colors, and curves. The deeper layers learn the higher level representation of image and search for complex shapes and structures. Mathematically deeper layers can be thought of as compositions of previous layers. \cite{alex}\cite{Zeiler}\cite{karparthy}. 

\begin{figure}[H]
\centering
\includegraphics[scale=1.5]{cnn.png}
\caption{CNN learning simple features on initial layers for different classes}
\end{figure}

Variants of CNNs have achieved great successes for morphological galaxy classification and prediction on SDSS\cite{Sander}. Sander Dieleman et al. won the Galaxy challenge, an international competition to build the best model for morphology
classication based on annotated images from the Galaxy Zoo project.

\section{Timeline}




\begin{vtimeline}[timeline color=cyan!80!blue, line offset=2pt]
26th April to 11th May & literature survey\endlr
Mid-August to October & Basic prototype model \endlr
October to November & choosing the approaches which work, and implementing them on all data validation of the results\endlr
November to December & Refining the system, cleaning and commenting the code\endlr
\end{vtimeline}


\section{Conclusion}
We would like to thank Dr.Yogesh Wadadekar \footnote{\label{NCRA-TIFR} National Center for Radio Astrophysics - Tata Institute of Fundamental Research}, Dr.C. H. Ishwara Chandra \footnotemark[\ref{NCRA-TIFR}] for their supportive presence during the process of brainstorming potential research ideas. Their constant guidance has been an invaluable source of inspiration for us, and we are eager to continue working with them.




\begin{thebibliography}{9}
\bibitem{alex} 
Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton. 
\textit{ImageNet Classification with Deep Convolutional
Neural Networks}. 

 
\bibitem{Zeiler} 
Matthew D. Zeiler, Rob Fergus.  
\textit{Visualizing and Understanding Convolutional Networks}.  
\newline arXiv print : 1311.2901v3, 2013.

\bibitem{karparthy} 
Andrej Karparthy, Fei-Fei Li, Justin Johnson, Serena Yeung.
\\\texttt{http://cs231n.github.io/convolutional-networks/}

\bibitem{Sander} 
Sander Dieleman, Kyle W. Willett and Joni Dambre  
\textit{Rotation-invariant convolutional neural networks for galaxy morphology prediction}.  
\newline arXiv print : 1503.0707v1, 2015.


\end{thebibliography}



\end{multicols*}
\end{document}
